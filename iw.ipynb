{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import torch\n",
    "import argparse\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from data import datasets\n",
    "import utils.utils as utils\n",
    "import plotting\n",
    "import os\n",
    "import einops \n",
    "import json\n",
    "from helpers import logging, create\n",
    "from manifold import Sphere\n",
    "from sdes import AmbientSphericalBrownianMotion, AmbientSphericalGenerative\n",
    "from models import ConcatMLP\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "_folder_name_keys = ['dataset', 'batch_size', 'lr', 'num_iterations', 'T0', 'emb_size', 'hidden_layers']\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # i/o\n",
    "    parser.add_argument('--dataset', type=str,\n",
    "                        choices=['UniformSlice', 'Earthquake', 'Fire', 'Volcano'],\n",
    "                        default='UniformSlice')\n",
    "    parser.add_argument('--dataroot', type=str, default='data')\n",
    "    parser.add_argument('--saveroot', type=str, default='saved')\n",
    "    parser.add_argument('--expname', type=str, default='sphere')\n",
    "    parser.add_argument('--print_every', type=int, default=100)\n",
    "    parser.add_argument('--sample_every', type=int, default=500)\n",
    "    parser.add_argument('--checkpoint_every', type=int, default=500)\n",
    "    parser.add_argument('--num_steps', type=int, default=100,\n",
    "                        help='number of integration steps for sampling')\n",
    "\n",
    "    # hparam\n",
    "    parser.add_argument('--T0', type=float, default=2.0,\n",
    "                        help='integration time')\n",
    "    parser.add_argument('--emb_size', type=int, default=256,\n",
    "                        help='num of hiddens')\n",
    "    parser.add_argument('--hidden_layers', type=int, default=2,\n",
    "                        help='num of hiddens')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--div', type=str, choices=['deterministic'], )\n",
    "    parser.add_argument('--batch_size', type=int, default=64)\n",
    "    parser.add_argument('--val_batch_size', type=int, default=256)\n",
    "    parser.add_argument('--test_batch_size', type=int, default=256)\n",
    "    parser.add_argument('--lr', type=float, default=0.001,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--num_iterations', type=int, default=10000)\n",
    "\n",
    "    return parser.parse_args(['--dataset' ,'UniformSlice'])\n",
    "\n",
    "\n",
    "args = get_args()\n",
    "folder_tag = 'riemannian-diffusion'\n",
    "folder_name = '-'.join([str(getattr(args, k)) for k in _folder_name_keys])\n",
    "create(args.saveroot, folder_tag, args.expname, folder_name)\n",
    "folder_path = os.path.join(args.saveroot, folder_tag, args.expname, folder_name)\n",
    "print_ = lambda s: logging(s, folder_path)\n",
    "print_(f'folder path: {folder_path}')\n",
    "print_(str(args))\n",
    "with open(os.path.join(folder_path, 'args.txt'), 'w') as out:\n",
    "    out.write(json.dumps(args.__dict__, indent=4))\n",
    "\n",
    "# wandb.init(project=\"riemannian-diffusion\", name=f'{args.expname}-{folder_name}', config=args.__dict__)\n",
    "\n",
    "if args.dataset == 'UniformSlice':\n",
    "    trainset = datasets.UniformPatchDataset(n=50000)\n",
    "    trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    valset = datasets.UniformPatchDataset(n=10000)\n",
    "    valloader = DataLoader(trainset, batch_size=args.val_batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    testset = datasets.UniformPatchDataset(n=10000)\n",
    "    testloader = DataLoader(trainset, batch_size=args.test_batch_size, shuffle=True, num_workers=0)\n",
    "elif args.dataset == 'Earthquake':\n",
    "    trainset = datasets.Earthquake()\n",
    "    trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    valset = datasets.Earthquake()\n",
    "    valloader = DataLoader(trainset, batch_size=args.val_batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    testset = datasets.Earthquake()\n",
    "    testloader = DataLoader(trainset, batch_size=args.test_batch_size, shuffle=True, num_workers=0)\n",
    "else:\n",
    "    raise Exception(f'Dataset {args.dataset} not implemented')\n",
    "\n",
    "a = ConcatMLP(3, 1, args.emb_size, args.hidden_layers)\n",
    "print_(a)\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "if cuda:\n",
    "    print('cuda available')\n",
    "    a = a.cuda()\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print('cuda unavailable')\n",
    "    device = 'cpu'\n",
    "\n",
    "sde = AmbientSphericalBrownianMotion(args.T0)\n",
    "gsde = AmbientSphericalGenerative(utils.get_drift(a, args.T0, Sphere, proj_div_proj=utils.zero_func))\n",
    "opt = torch.optim.Adam(a.parameters(), lr=args.lr)\n",
    "count = 0\n",
    "\n",
    "if os.path.exists(os.path.join(folder_path, 'checkpoint.pt')):\n",
    "    a, opt, not_finished, count = torch.load(os.path.join(folder_path, 'checkpoint.pt'))\n",
    "    gsde = AmbientSphericalGenerative(utils.get_drift(a, args.T0, Sphere, proj_div_proj=utils.zero_func))\n",
    "    pass\n",
    "else:\n",
    "    not_finished = True\n",
    "    count = 0\n",
    "\n",
    "    a.eval()\n",
    "#     wandb.log(\n",
    "#         {'samples': wandb.Image(plotting.plot_scatter3D(gsde.sample(utils.sample_spherical_uniform(n=1024).to(device),\n",
    "                                                                    args.T0, args.num_steps).detach().cpu().numpy()))},\n",
    "        step=count)\n",
    "    a.train()\n",
    "\n",
    "#     wandb.log({'test data': wandb.Image(plotting.plot_scatter3D(testset.data[:1024]))},\n",
    "#               step=count)\n",
    "\n",
    "while not_finished:\n",
    "    for x in trainloader:\n",
    "        t = utils.stratified_uniform(x.size(0), args.T0)\n",
    "        y = sde.sample(x, t).requires_grad_(True)\n",
    "        if cuda:\n",
    "            y = y.cuda()\n",
    "            t = t.cuda()\n",
    "\n",
    "        loss = - utils.elbo(y, t, a, Sphere.proj2manifold, Sphere.proj2tangent, args.T0, utils.zero_func,\n",
    "                            utils.zero_func).mean()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        count += 1\n",
    "#         wandb.log({'loss': loss.item()}, step=count)\n",
    "        if count % args.print_every == 0 or count == 1:\n",
    "            print_(f'Iteration {count} \\tloss {loss.item()}')\n",
    "\n",
    "        if count % args.sample_every == 0:\n",
    "            a.eval()\n",
    "#             wandb.log(\n",
    "#                 {'samples': wandb.Image(\n",
    "#                     plotting.plot_scatter3D(gsde.sample(utils.sample_spherical_uniform(n=1024).to(device),\n",
    "#                                                         args.T0,\n",
    "#                                                         args.num_steps).detach().cpu().numpy()))},\n",
    "#                 step=count)\n",
    "            a.train()\n",
    "\n",
    "        if count % args.checkpoint_every == 0:\n",
    "            torch.save([a, opt, not_finished, count], os.path.join(folder_path, 'checkpoint.pt'))\n",
    "\n",
    "        if count >= args.num_iterations:\n",
    "            not_finished = False\n",
    "            print_('Finished training')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.elbo(y, t, a, Sphere.proj2manifold, Sphere.proj2tangent, args.T0, utils.zero_func,\n",
    "                            utils.zero_func).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponent_step(y, s, a_func, proj2manifold, proj2tangent, ds, db, proj_div_proj=None, div_proj_div_proj=None):\n",
    "    py = proj2manifold(y)\n",
    "    a = a_func(py, s)\n",
    "    pa = proj2tangent(py, a)\n",
    "    \n",
    "    if proj_div_proj is not None:\n",
    "        pdp = proj_div_proj(py)\n",
    "    else:\n",
    "        raise NotImplementedError  # TODO\n",
    "        \n",
    "    v0 = pdp + pa\n",
    "\n",
    "    div_v0 = 0\n",
    "    for i in range(y.size(1)):\n",
    "        div_v0 += torch.autograd.grad(v0[:, i].sum(), y, create_graph=False, retain_graph=True)[0][:, i]\n",
    "\n",
    "    if div_proj_div_proj is not None:\n",
    "        dpdp = div_proj_div_proj(y)\n",
    "    else:\n",
    "        raise NotImplementedError  # TODO\n",
    "        \n",
    "    A = (a*db).sum(axis=-1)\n",
    "    B = (-0.5 * (a ** 2).sum(dim=1) - div_v0 + 0.5 * dpdp)*ds\n",
    "    \n",
    "    return  A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdes import midpoint_step\n",
    "from utils.utils import LOG_SPHERICAL_UNIFORM\n",
    "\n",
    "def integrate_elbok(sde, y0, a_func, proj2manifold, proj2tangent, T, K, steps: int = 1000,\n",
    "          proj_div_proj=None,\n",
    "          div_proj_div_proj=None):\n",
    "    \n",
    "    expos = []\n",
    "    for _ in range(K):\n",
    "        y_next = y0\n",
    "        s = 0\n",
    "        ds = T / steps\n",
    "        expo = torch.zeros(y0.shape[0]).to(y0)+LOG_SPHERICAL_UNIFORM\n",
    "        for _ in range(steps):\n",
    "            s += ds\n",
    "            y = y_next.detach().requires_grad_(True)\n",
    "            y_next, increment = midpoint_step(s, ds, y, sde.f, sde.g_increment, proj2manifold, return_increment=True)\n",
    "            expo_step = exponent_step(y=y,s=s,a_func=a,\n",
    "                      proj2manifold=proj2manifold,\n",
    "                      proj2tangent=proj2tangent, \n",
    "                      ds=ds,\n",
    "                      db=increment, \n",
    "                      proj_div_proj=utils.zero_func,\n",
    "                      div_proj_div_proj=utils.zero_func)\n",
    "            expo = expo_step.detach() + expo\n",
    "        expos.append(expo)\n",
    "        \n",
    "    #sum different samples \n",
    "    expos = torch.stack(expos, axis=1) # [batch_size, K]\n",
    "    logK = torch.log(torch.tensor(K)).to(x0)\n",
    "    elbok = torch.logsumexp(expos, dim=1)-logK\n",
    "    \n",
    "    return elbok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_elbok_parallel(sde, y0, a_func, proj2manifold, proj2tangent, T, K, steps: int = 1000,\n",
    "          proj_div_proj=None,\n",
    "          div_proj_div_proj=None):\n",
    "    \n",
    "    #adding K copies of the data so I can parallelize the sampling\n",
    "    y0 = repeat(y0, 'b d -> b k d', k=K)\n",
    "    y0 = rearrange(y0, 'b k d -> (b k) d')\n",
    "    \n",
    "    y_next = y0\n",
    "    s = 0\n",
    "    ds = T / steps\n",
    "    expo = torch.zeros(y0.shape[0]).to(y0)+LOG_SPHERICAL_UNIFORM\n",
    "    for _ in range(steps):\n",
    "        s += ds\n",
    "        y = y_next.detach().requires_grad_(True)\n",
    "        y_next, increment = midpoint_step(s, ds, y, sde.f, sde.g_increment, proj2manifold, return_increment=True)\n",
    "        expo_step = exponent_step(y=y,s=s,a_func=a,\n",
    "                  proj2manifold=proj2manifold,\n",
    "                  proj2tangent=proj2tangent, \n",
    "                  ds=ds,\n",
    "                  db=increment, \n",
    "                  proj_div_proj=utils.zero_func,\n",
    "                  div_proj_div_proj=utils.zero_func)\n",
    "        expo = expo_step.detach() + expo\n",
    "    \n",
    "    expo = rearrange(expo, '(b k) -> b k', k=K)\n",
    "    logK = torch.log(torch.tensor(K)).to(x0)\n",
    "    elbok = torch.logsumexp(expo, dim=1)-logK\n",
    "    \n",
    "    return elbok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "steps = 1000\n",
    "x0 = next(iter(trainloader)) # [batch_size, manifold_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x0[0:1].repeat(500, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbok1 = integrate_elbok(sde, X, a, Sphere.proj2manifold, Sphere.proj2tangent, sde.T, 1, steps=1000)\n",
    "elbok4 = integrate_elbok(sde, X, a, Sphere.proj2manifold, Sphere.proj2tangent, sde.T, 4, steps=1000)\n",
    "elbok10 = integrate_elbok(sde, X, a, Sphere.proj2manifold, Sphere.proj2tangent, sde.T, 10, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASM0lEQVR4nO3df7BkZ13n8fdnE8kK4iY4d+IIiZOhArXB0oneirtLYmUJYki5RJSNmbI0CJUhrqHWUssNYAGla5W/IuWya1KTJZWwBSFIjKTcsBJRSZESdCYMw4QkZiaGYsZh5hJ2EQ2V3STf/aPPxeame6bvPd237zy+X1Vd9/Rzfn3n9Lmf+8zTp0+nqpAkteWfzbsASdL0Ge6S1CDDXZIaZLhLUoMMd0lq0KnzLgBg06ZNtXXr1nmXIUknlT179nypqhZGzdsQ4b5161Z279497zIk6aSS5PPj5jksI0kNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDdoQn1CVJIBjTxyby343P3fzXPY7S/bcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoNOGO5Jbk5yLMn+obbbk+ztHo8l2du1b03ytaF5N86wdknSGJNc534L8F+B9y43VNWPL08nuR74ytDyB6tq+5TqkyStwQnDvaruTbJ11LwkAa4AXjHluiRJPfQdc78IOFpVjwy1nZPk00k+nuSicSsm2Zlkd5LdS0tLPcuQJA3rG+47gNuGnh8Bzq6q84GfB96f5FtHrVhVu6pqsaoWFxZGfnm3JGmN1hzuSU4FfhS4fbmtqp6sqse76T3AQeAlfYuUJK1On577K4GHqurQckOShSSndNPbgHOBR/uVKElarUkuhbwN+AvgpUkOJXljN+tKvnFIBuAHgH3dpZEfAq6pqi9PsV5J0gQmuVpmx5j2149ouwO4o39ZkqQ+/ISqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNeiE38QkSa079sSxue1783M3z2S79twlqUGTfEH2zUmOJdk/1PbOJIeT7O0elw3Ne0uSA0keTvJDsypckjTeJD33W4BLR7S/q6q2d4+7AZKcB1wJvKxb5/eSnDKtYiVJkzlhuFfVvcCXJ9ze5cAHqurJqvob4ABwQY/6JElr0GfM/dok+7phmzO6thcCXxha5lDX9ixJdibZnWT30tJSjzIkSSutNdxvAF4MbAeOANevdgNVtauqFqtqcWFhYY1lSJJGWVO4V9XRqnq6qp4BbuIfh14OA2cNLfqirk2StI7WFO5Jtgw9fS2wfCXNXcCVSU5Lcg5wLvCX/UqUJK3WCT/ElOQ24GJgU5JDwDuAi5NsBwp4DHgTQFU9kOSDwOeAp4CfraqnZ1K5JGmsE4Z7Ve0Y0fye4yz/a8Cv9SlKktSPn1CVpAZ5bxlJbbvv3cef//I3r08d68yeuyQ1yJ67pH/aTtSzh5Oyd2/PXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAadMNyT3JzkWJL9Q22/leShJPuS3Jnk9K59a5KvJdnbPW6cYe2SpDEm6bnfAly6ou0e4Luq6ruBvwbeMjTvYFVt7x7XTKdMSdJqnPCbmKrq3iRbV7R9dOjpJ4HXTbkuSZq5mz7x6Nenr75w2xwrmb5pjLm/AfjI0PNzknw6yceTXDRupSQ7k+xOsntpaWkKZUiSlvUK9yRvA54C3tc1HQHOrqrzgZ8H3p/kW0etW1W7qmqxqhYXFhb6lCFJWmHN4Z7k9cAPAz9RVQVQVU9W1ePd9B7gIPCSKdQpSVqFNYV7kkuBXwJeU1VPDLUvJDmlm94GnAs8OnorkqRZOeEbqkluAy4GNiU5BLyDwdUxpwH3JAH4ZHdlzA8Av5Lk/wHPANdU1ZdnVLskaYxJrpbZMaL5PWOWvQO4o29RkqR+/ISqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KCJwj3JzUmOJdk/1PaCJPckeaT7eUbXniT/JcmBJPuSfO+sipckjTZpz/0W4NIVbdcBH6uqc4GPdc8BXg2c2z12Ajf0L1OStBoThXtV3Qt8eUXz5cCt3fStwI8Mtb+3Bj4JnJ5kyxRqlSRNqM+Y+5lVdaSb/iJwZjf9QuALQ8sd6tq+QZKdSXYn2b20tNSjDEnSSlN5Q7WqCqhVrrOrqharanFhYWEaZUiSOn3C/ejycEv381jXfhg4a2i5F3VtkqR10ifc7wKu6qavAj481P5T3VUz/wr4ytDwjSRpHZw6yUJJbgMuBjYlOQS8A/h14INJ3gh8HriiW/xu4DLgAPAE8NNTrlmS1uSmTzw67xLWzUThXlU7xsy6ZMSyBfxsn6IkSf34CVVJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkho00XXuktS6lR9wuvrCbXOqZDrsuUtSgwx3SWqQwzKSTl73vXveFWxY9twlqUH23CU9y7Enjp14IW1o9twlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg9Z8KWSSlwK3DzVtA94OnA5cDSx17W+tqrvXuh9J0uqtOdyr6mFgO0CSU4DDwJ3ATwPvqqrfnkaBkqTVm9awzCXAwar6/JS2J0nqYVrhfiVw29Dza5PsS3JzkjNGrZBkZ5LdSXYvLS2NWkSStEa9wz3Jc4DXAL/fNd0AvJjBkM0R4PpR61XVrqparKrFhYWFvmVIkoZMo+f+auD+qjoKUFVHq+rpqnoGuAm4YAr7kCStwjTCfQdDQzJJtgzNey2wfwr7kCStQq+7QiZ5HvCDwJuGmn8zyXaggMdWzJMkrYNe4V5V/wB824q2n+xVkSSpNz+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDWo13eoAiR5DPgq8DTwVFUtJnkBcDuwlcGXZF9RVf+7774kSZPpHe6df1tVXxp6fh3wsar69STXdc//05T2JUnr6753H3/+y9+8PnWswrTCfaXLgYu76VuBP8dwl7TObvrEo/MuYW6mMeZewEeT7Emys2s7s6qOdNNfBM6cwn4kSROaRs/9wqo6nGQzcE+Sh4ZnVlUlqZUrdX8IdgKcffbZUyhDkrSsd8+9qg53P48BdwIXAEeTbAHofh4bsd6uqlqsqsWFhYW+ZUiShvQK9yTPS/L85WngVcB+4C7gqm6xq4AP99mPJGl1+g7LnAncmWR5W++vqv+V5K+ADyZ5I/B54Iqe+5EkrUKvcK+qR4HvGdH+OHBJn21L0jytvNLm6gu3zamStfETqpLUIMNdkhpkuEtSgwx3SWqQ4S5JDZrVvWUkqb8T3bBLYxnukprxT/lGYSs5LCNJDTLcJalBhrskNchwl6QG+YaqtEEde+JZd8qWJmbPXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgNX+IKclZwHuBM4ECdlXV7yZ5J3A1sNQt+taqurtvoZK0kneBHK/PJ1SfAn6hqu5P8nxgT5J7unnvqqrf7l+eJGkt1hzuVXUEONJNfzXJg8ALp1WYJGntpjLmnmQrcD7wqa7p2iT7ktyc5Iwx6+xMsjvJ7qWlpVGLSJLWqHe4J/kW4A7g56rq74AbgBcD2xn07K8ftV5V7aqqxapaXFhY6FuGJGlIr3BP8k0Mgv19VfUHAFV1tKqerqpngJuAC/qXKUlajT5XywR4D/BgVf3OUPuWbjwe4LXA/n4lSvPlrXd1MupztczLgZ8EPptkb9f2VmBHku0MLo98DHhTj31Iktagz9UynwAyYpbXtEvSnPkJVUlqkOEuSQ0y3CWpQX5BtqT5uO/d866gafbcJalBhrskNchhGUmawMrbC1994bY5VTIZe+6S1CB77jopeAsAaXXsuUtSgwx3SWqQ4S5JDTLcJalBvqEqSX1N8mnbl7959nUMMdwlnTRWXmuu8Qx3Sd9oA/ZCtXqGu1bF682lk4NvqEpSg+y5n4TsPWvDm+LtfB1nX5uZ9dyTXJrk4SQHklw3q/1Ikp5tJuGe5BTgvwGvBs4DdiQ5bxb7kiQ926yGZS4ADlTVowBJPgBcDnxuFjub1zDF5udunst+pbnzW5Q2vFmF+wuBLww9PwR8//ACSXYCO7unf5/k4R772wR8qcf66816Z8t6Z8t6gV9e9Rr/edIFV1Pvd46bMbc3VKtqF7BrGttKsruqFqexrfVgvbNlvbNlvbM1rXpn9YbqYeCsoecv6tokSetgVuH+V8C5Sc5J8hzgSuCuGe1LkrTCTIZlquqpJNcCfwycAtxcVQ/MYl+dqQzvrCPrnS3rnS3rna3pDFdX1TS2I0naQLz9gCQ1yHCXpAadFOGe5N8neSDJM0kWh9q3Jvlakr3d48Yx678gyT1JHul+njGnen8wyZ4kn+1+vmLM+u9Mcnjo33XZPOrt5r2lu4XEw0l+aMz65yT5VLfc7d2b6Oui29/ycXosyd4xyz3WHfe9SXavV31japno9d0It/BI8ltJHkqyL8mdSU4fs9xcj++JjlWS07pz5UB3rm5d7xqHajkryZ8l+Vz3e/cfRyxzcZKvDJ0jb1/1jqpqwz+Afwm8FPhzYHGofSuwf4L1fxO4rpu+DviNOdV7PvAd3fR3AYfHrP9O4Bc3wPE9D/gMcBpwDnAQOGXE+h8EruymbwR+Zk7nyfXA28fMewzYNI+61vL6MrgQ4SCwDXhO9zqcN4daXwWc2k3/xrjfnXke30mOFfAfgBu76SuB2+f4+m8Bvrebfj7w1yPqvRj4oz77OSl67lX1YFX1+QTr5cCt3fStwI/0Luo4xtVbVZ+uqr/tnj4AfHOS02ZZyySOc3wvBz5QVU9W1d8ABxjcWuLrkgR4BfChrmnmx3eUro4rgNvWe98z8vVbeFTV/wWWb+Gxrqrqo1X1VPf0kww+s7LRTHKshjPgQ8Al3Tmz7qrqSFXd301/FXiQwaf6p+qkCPcTOCfJp5N8PMlFY5Y5s6qOdNNfBM5cp9qO58eA+6vqyTHzr+3+K3zzrIeRjmPUbSRWnoTfBvyfoQAYtcx6uAg4WlWPjJlfwEe74bCdY5ZZTyd6fSc59uvtDcBHxsyb5/Gd5Fh9fZnuXP0Kg3N3rrrhofOBT42Y/a+TfCbJR5K8bLXb3jD3c0/yJ8C3j5j1tqr68JjVjgBnV9XjSb4P+MMkL6uqvxu3n6qqJL2v/1xjvcvrvozBf3FfNWaRG4BfZfAL86sMhhvesPZq+9U7bxPWvoPj99ovrKrDSTYD9yR5qKrunXaty45XMzN4ffuY5PgmeRvwFPC+MZtZ1+PbgiTfAtwB/NyIzLof+M6q+vvuPZk/BM5dzfY3TLhX1SvXsM6TwJPd9J4kB4GXACvf0DmaZEtVHUmyBeh9G8m11AuQ5EXAncBPVdXBMds+OrT8TcAfranIb9zmWuqd5DYSjwOnJzm16xFN/VYTJ6o9yanAjwLfd5xtHO5+HktyJ4P/ys8sfCY93sd5fdftFh4THN/XAz8MXFLdgPCIbazr8V1hkmO1vMyh7nz5FwzO3blI8k0Mgv19VfUHK+cPh31V3Z3k95JsqqqJb4B2Ug/LJFnI4N7xJNnG4C/bqK9tuQu4qpu+CphLT7W70uB/Mnhz977jLLdl6Olrgf0zLm2cu4AruysNzmFwfP9yeIHul/3PgNd1TfM4vq8EHqqqQ6NmJnlekucvTzP4H9O8jumkr++GuIVHkkuBXwJeU1VPjFlm3sd3kmM1nAGvA/503B+qWevG+t8DPFhVvzNmmW9ffk8gyQUMsnp1f4zm9Y7xah4MfgEOMeilHwX+uGv/MQZvTO5l8N+Yfze0zn+nu/KDwdjax4BHgD8BXjCnen8Z+Ieu3uXH5hH1/g/gs8A+BifllnnU2817G4MrER4GXj3Ufjf/eOXPNgahfwD4feC0dT4/bgGuWdH2HcDdQ/V9pns8wGC4YZ7n88jXd7jm7vllDK6kODivmrvX9AtD5+uNK2vdCMd31LECfoXBHyWAf96dmwe6c3XbHF//CxkMye0bOq6XAdcsn8fAtd2x/AyDN7L/zWr34+0HJKlBJ/WwjCRpNMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNej/A35m6kcyswa3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(elbok10.detach().numpy(),)\n",
    "plt.hist(elbok4.detach().numpy(), alpha=0.5)\n",
    "plt.hist(elbok1.detach().numpy(), alpha=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8898)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elbok1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2383)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elbok4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3962)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elbok10.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
